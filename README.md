# Taiwan_opendata_processing

![](https://i.imgur.com/0jYCmpz.png)

## 前情提要
  台灣政府開放資料平台擁有龐大的資料，可以被各領域應用。但很多資料品質不佳，有一些小問題，造成使用上不是這麼方便。像是編碼格式不一、重複變數名稱、資料第一行第二行包含無意義資訊，一整行或列全部NA等，雖然人工來說，不難處理，但每次利用時，都有類似的問題，造成使用者不便或觀感不佳，因此建立自動清理程式，完善大部分資料的小問題。  
  此外，政府開放資料平台上，很多資料集標籤有誤，因類別並無仔細定義清楚，且未仔細審核，導致後來上傳資料者，為了方便皆填寫公共資訊，導致此項資訊幫助不大，因此透過爬蟲獲取資料集標籤，並重組資料，提升資料品質，最後建立分類模型，以期能改善大部分資料皆被分成公共資訊，以及部分資料貼錯標籤等現象，達到標籤資訊有實質意義的目標。


## 下載政府開放資料
  從國網中心開放資料集平台(scidm)政府開放資料組織下，下載全部資料，並找出所有csv檔(一般民眾常用檔案格式，最類似xlsx)，如下圖:
  
 ![](https://i.imgur.com/AEy2ISq.png)
 
 因為scidm為ckan架構的網站，有內建的API，會較容易處理。
 
 程式碼邏輯:
 設定網址:ckanr_setup(url='https://scidm.nchc.org.tw/') =>
 
 找出政府開放資料的id:organization_list()  =>
 
 讀取處理過的資料:fread(dealt_path) =>
 
 讀取所有的資料集編號:package_list(limit=10^5)  =>
 
 讀取最新更新檔案:changes(limit=update_num) =>
  
 如果最新檔案id有出現在已處過檔案，判別最後修改日期是否一致。
 是代表不用更新，否代表要更新。如果有不在處理過的資料集，需增加到下載清單裡。
 扣掉所有已處理且不需更新的資料集編號，並找出前面數來download_num個數，即為此次需要下載的資料集編號 =>
 
 讀取資料集資訊:package_show(id) =>
 
 下載與紀錄:curl_download(url,save_path);writeLines(Description_content) =>
 
 結束
 ## 資料清理
  
